{"cells":[{"cell_type":"code","source":["import zipfile\n","import os\n","import tensorflow as tf\n","from tensorflow.keras import layers, models, regularizers, optimizers, callbacks\n","import numpy as np\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report"],"metadata":{"id":"eDErWkZrHTEE"},"id":"eDErWkZrHTEE","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"9Bp-l67wF4ei","colab":{"base_uri":"https://localhost:8080/"},"outputId":"85f1772d-de39-4940-ac4f-357cc1d6da30"},"id":"9Bp-l67wF4ei","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["Dataset Loading"],"metadata":{"id":"2xJcX0iaMDk9"},"id":"2xJcX0iaMDk9"},{"cell_type":"code","source":["zip_file_path = '/content/drive/MyDrive/MLMA Project/GROUPBY SPLIT/Use This Final Final (22 04 25)/augumented_final.zip' # Path to zipped dataset\n","extract_folder = '/content/Finaldata' # Path to unzip\n","if not os.path.exists(extract_folder):\n","    os.makedirs(extract_folder)\n","try:\n","    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n","        zip_ref.extractall(extract_folder)\n","    print(f\"Successfully extracted {zip_file_path} to {extract_folder}\")\n","except FileNotFoundError:\n","    print(f\"Error: Zip file not found at {zip_file_path}\")\n","except Exception as e:\n","    print(f\"An error occurred: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZLIahzWxxKZY","outputId":"442b14bd-cec6-480f-8368-00a45f2703f7"},"id":"ZLIahzWxxKZY","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Successfully extracted /content/drive/MyDrive/MLMA Project/GROUPBY SPLIT/Use This Final Final (22 04 25)/augumented_final.zip to /content/Finaldata\n"]}]},{"cell_type":"code","source":["BATCH_SIZE = 32\n","IMG_SIZE = (299, 299)\n","EPOCHS = 10\n","train_dir = r\"/content/Finaldata/augumented_final/train\"\n","valid_dir = r\"/content/Finaldata/augumented_final/valid\"\n","test_dir  = r\"/content/Finaldata/augumented_final/test\""],"metadata":{"id":"BA7b9lv2QP6n"},"id":"BA7b9lv2QP6n","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load train, validation and test sets\n","train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","    train_dir,\n","    label_mode=\"int\",\n","    image_size=IMG_SIZE,\n","    batch_size=BATCH_SIZE,\n","    shuffle=True\n",")\n","val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","    valid_dir,\n","    label_mode=\"int\",\n","    image_size=IMG_SIZE,\n","    batch_size=BATCH_SIZE,\n","    shuffle=False\n",")\n","test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","    test_dir,\n","    label_mode=\"int\",\n","    image_size=IMG_SIZE,\n","    batch_size=BATCH_SIZE,\n","    shuffle=False\n",")\n","class_names = train_ds.class_names\n","num_classes = len(class_names)\n","print(\"Classes:\", class_names)\n","AUTOTUNE = tf.data.AUTOTUNE\n","train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n","val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n","test_ds = test_ds.prefetch(buffer_size=AUTOTUNE)"],"metadata":{"id":"_Y7Sx7GhQvUM","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3fa3a636-14a1-45ed-ca3f-b779102e82ac"},"id":"_Y7Sx7GhQvUM","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 8958 files belonging to 8 classes.\n","Found 1282 files belonging to 8 classes.\n","Found 631 files belonging to 8 classes.\n","Classes: ['A', 'C', 'D', 'G', 'H', 'M', 'N', 'O']\n"]}]},{"cell_type":"code","source":["class_counts = np.zeros(num_classes, dtype=int)\n","for images, labels in train_ds.unbatch():\n","    class_counts[labels.numpy()] += 1\n","print(\"Class counts:\", class_counts)\n","class_weights = {i: float(num_classes/count) for i, count in enumerate(class_counts)}   # Compute class weights\n","print(\"Class weights:\", class_weights)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MtDojwjELx-r","outputId":"536ff44c-e641-49da-b2e5-5ec3e6637f0d"},"id":"MtDojwjELx-r","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Class counts: [ 370  414 2262  388  182  338 4032  972]\n","Class weights: {0: 0.021621621621621623, 1: 0.01932367149758454, 2: 0.0035366931918656055, 3: 0.020618556701030927, 4: 0.04395604395604396, 5: 0.023668639053254437, 6: 0.001984126984126984, 7: 0.00823045267489712}\n"]}]},{"cell_type":"markdown","source":["XceptionNet Training and Evaluation"],"metadata":{"id":"M4ne-ub5LKAs"},"id":"M4ne-ub5LKAs"},{"cell_type":"code","source":["# Function to build XceptionNet model\n","\n","def build_xception_model(learning_rate, weight_decay):\n","    base_model = tf.keras.applications.Xception(\n","        weights='imagenet', include_top=False, input_shape=IMG_SIZE + (3,)\n","    )\n","    base_model.trainable = False  # Freeze the base model\n","    inputs = tf.keras.Input(shape=IMG_SIZE + (3,))\n","    x = tf.keras.applications.xception.preprocess_input(inputs)\n","    x = base_model(x, training=False)\n","    x = layers.GlobalAveragePooling2D()(x)\n","    outputs = layers.Dense(num_classes, activation=\"softmax\",\n","                           kernel_regularizer=regularizers.l2(weight_decay))(x)\n","    model = tf.keras.Model(inputs, outputs)\n","    model.compile(\n","        optimizer=optimizers.Adam(learning_rate=learning_rate),\n","        loss=\"sparse_categorical_crossentropy\",\n","        metrics=[\"accuracy\"]\n","    )\n","    return model\n","\n","# Define hyperparameters\n","learning_rates = [1e-3, 5e-4]\n","weight_decays = [0.0, 1e-4]\n","\n","best_val_acc = 0.0\n","best_config = None\n","best_model = None\n","\n","# Hyperparamter tuning\n","for lr in learning_rates:\n","    for wd in weight_decays:\n","        print(f\"\\nTraining configuration: lr={lr}, weight_decay={wd}\")\n","        model = build_xception_model(learning_rate=lr, weight_decay=wd)\n","        earlystop = callbacks.EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True) # Early stopping\n","\n","        # Train the model\n","        history = model.fit(\n","            train_ds,\n","            validation_data=val_ds,\n","            epochs=EPOCHS,\n","            callbacks=[earlystop],\n","            class_weight=class_weights,\n","            verbose=1\n","        )\n","\n","        max_val_acc = max(history.history['val_accuracy'])\n","        print(f\"Config: lr={lr}, wd={wd} -- Best validation accuracy: {max_val_acc:.4f}\")\n","        if max_val_acc > best_val_acc:\n","            best_val_acc = max_val_acc\n","            best_config = (lr, wd)\n","            best_model = model   # Model with the best validation accuracy\n","\n","print(f\"\\nBest hyperparameters: lr={best_config[0]}, weight_decay={best_config[1]}\")\n","print(f\"Best validation accuracy: {best_val_acc:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MWbAgH50L0OP","outputId":"269d7bdd-e340-48b5-fc7b-fe551bc9548c"},"id":"MWbAgH50L0OP","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Training configuration: lr=0.001, weight_decay=0.0\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n","\u001b[1m83683744/83683744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n","Epoch 1/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 117ms/step - accuracy: 0.2238 - loss: 0.0126 - val_accuracy: 0.3284 - val_loss: 1.6914\n","Epoch 2/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - accuracy: 0.3491 - loss: 0.0095 - val_accuracy: 0.2387 - val_loss: 1.8703\n","Epoch 3/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - accuracy: 0.3743 - loss: 0.0088 - val_accuracy: 0.3175 - val_loss: 1.7728\n","Epoch 4/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - accuracy: 0.4004 - loss: 0.0083 - val_accuracy: 0.2800 - val_loss: 1.7894\n","Config: lr=0.001, wd=0.0 -- Best validation accuracy: 0.3284\n","\n","Training configuration: lr=0.001, weight_decay=0.0001\n","Epoch 1/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 56ms/step - accuracy: 0.2341 - loss: 0.0136 - val_accuracy: 0.2379 - val_loss: 1.8563\n","Epoch 2/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.3033 - loss: 0.0109 - val_accuracy: 0.3237 - val_loss: 1.7062\n","Epoch 3/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - accuracy: 0.3170 - loss: 0.0105 - val_accuracy: 0.2754 - val_loss: 1.7690\n","Epoch 4/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - accuracy: 0.3363 - loss: 0.0104 - val_accuracy: 0.3097 - val_loss: 1.7438\n","Epoch 5/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - accuracy: 0.3374 - loss: 0.0103 - val_accuracy: 0.2793 - val_loss: 1.7252\n","Config: lr=0.001, wd=0.0001 -- Best validation accuracy: 0.3237\n","\n","Training configuration: lr=0.0005, weight_decay=0.0\n","Epoch 1/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 55ms/step - accuracy: 0.1865 - loss: 0.0132 - val_accuracy: 0.3120 - val_loss: 1.7470\n","Epoch 2/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.3295 - loss: 0.0101 - val_accuracy: 0.2910 - val_loss: 1.7628\n","Epoch 3/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.3439 - loss: 0.0095 - val_accuracy: 0.3885 - val_loss: 1.6591\n","Epoch 4/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - accuracy: 0.3756 - loss: 0.0090 - val_accuracy: 0.3003 - val_loss: 1.7087\n","Epoch 5/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - accuracy: 0.3877 - loss: 0.0087 - val_accuracy: 0.3721 - val_loss: 1.6691\n","Epoch 6/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - accuracy: 0.4104 - loss: 0.0084 - val_accuracy: 0.3401 - val_loss: 1.6594\n","Config: lr=0.0005, wd=0.0 -- Best validation accuracy: 0.3885\n","\n","Training configuration: lr=0.0005, weight_decay=0.0001\n","Epoch 1/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 56ms/step - accuracy: 0.2106 - loss: 0.0144 - val_accuracy: 0.2527 - val_loss: 1.7800\n","Epoch 2/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.3114 - loss: 0.0114 - val_accuracy: 0.2644 - val_loss: 1.7942\n","Epoch 3/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.3215 - loss: 0.0108 - val_accuracy: 0.2839 - val_loss: 1.7096\n","Epoch 4/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.3370 - loss: 0.0106 - val_accuracy: 0.3261 - val_loss: 1.7020\n","Epoch 5/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.3518 - loss: 0.0104 - val_accuracy: 0.3768 - val_loss: 1.6348\n","Epoch 6/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - accuracy: 0.3464 - loss: 0.0104 - val_accuracy: 0.3089 - val_loss: 1.7172\n","Epoch 7/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.3410 - loss: 0.0102 - val_accuracy: 0.2824 - val_loss: 1.7189\n","Epoch 8/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - accuracy: 0.3565 - loss: 0.0102 - val_accuracy: 0.3198 - val_loss: 1.7090\n","Config: lr=0.0005, wd=0.0001 -- Best validation accuracy: 0.3768\n","\n","Best hyperparameters: lr=0.0005, weight_decay=0.0\n","Best validation accuracy: 0.3885\n"]}]},{"cell_type":"code","source":["# Evaluate the best model on the test set\n","\n","y_true = []\n","y_pred = []\n","for images, labels in test_ds:\n","    preds = best_model.predict(images)\n","    y_true.extend(labels.numpy()) # True labels\n","    y_pred.extend(np.argmax(preds, axis=1).tolist()) # Predictions\n","y_true = np.array(y_true)\n","y_pred = np.array(y_pred)\n","\n","# Compute metrics\n","acc       = accuracy_score(y_true, y_pred)\n","prec_w    = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n","rec_w     = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n","f1_w      = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n","\n","# Print results\n","print(f\"Overall Test Accuracy : {acc:.4f}\")\n","print(f\"Weighted Precision   : {prec_w:.4f}\")\n","print(f\"Weighted Recall      : {rec_w:.4f}\")\n","print(f\"Weighted F1 Score    : {f1_w:.4f}\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NBSoDPW2Pg8J","outputId":"bbe2e7aa-8aa8-4c5f-feee-0a8451f2058a"},"id":"NBSoDPW2Pg8J","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step\n","Overall Test Accuracy : 0.3978\n","Weighted Precision   : 0.4869\n","Weighted Recall      : 0.3978\n","Weighted F1 Score    : 0.4194\n","\n"]}]},{"source":["model_save_path = \"/content/best_model.keras\"\n","best_model.save(model_save_path)   # Save the best model\n","print(f\"Best model saved to: {model_save_path}\")"],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MmKN2vXVUwlm","outputId":"151cabd4-be35-49ea-fd87-a4174912de44"},"id":"MmKN2vXVUwlm","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best model saved to: /content/best_model.keras\n"]}]},{"cell_type":"markdown","source":["MobileNetV3 Training and Evaluation"],"metadata":{"id":"gCz61XltLEuX"},"id":"gCz61XltLEuX"},{"cell_type":"code","source":["# Function to build MobileNetV3 model\n","\n","def build_mobilenetv3_model(lr, wd):\n","    base = tf.keras.applications.MobileNetV3Large(\n","        input_shape=IMG_SIZE + (3,),\n","        include_top=False, weights=\"imagenet\"\n","    )\n","    base.trainable = False # Freeze the base model\n","    inputs = layers.Input(shape=IMG_SIZE + (3,))\n","    x = tf.keras.applications.mobilenet_v3.preprocess_input(inputs)\n","    x = base(x, training=False)\n","    x = layers.GlobalAveragePooling2D()(x)\n","    outputs = layers.Dense(\n","        num_classes, activation=\"softmax\",\n","        kernel_regularizer=regularizers.l2(wd)\n","    )(x)\n","    model = models.Model(inputs, outputs)\n","    model.compile(\n","        optimizer=optimizers.Adam(learning_rate=lr),\n","        loss=\"sparse_categorical_crossentropy\",\n","        metrics=[\"accuracy\"]\n","    )\n","    return model"],"metadata":{"id":"hcmUrRe6SF3Z"},"id":"hcmUrRe6SF3Z","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define hyperparameters\n","learning_rates = [1e-3, 5e-4]\n","weight_decays  = [0.0, 1e-4]\n","\n","best_val_acc = 0.0\n","best_config  = None\n","best_model   = None.\n","\n","# Hyperparameter tuning\n","for lr in learning_rates:\n","    for wd in weight_decays:\n","        print(f\"\\nTraining MobileNetV3 with lr={lr}, weight_decay={wd}\")\n","        model = build_mobilenetv3_model(lr, wd)\n","        es = callbacks.EarlyStopping(\n","            monitor=\"val_accuracy\", patience=3,\n","            restore_best_weights=True\n","        )                                             # Early stopping\n","\n","        # Train the model\n","        history = model.fit(\n","            train_ds,\n","            validation_data=val_ds,\n","            epochs=EPOCHS,\n","            class_weight=class_weights,\n","            callbacks=[es],\n","            verbose=1\n","        )\n","        val_acc = max(history.history[\"val_accuracy\"])\n","        print(f\" → Best val_accuracy: {val_acc:.4f}\")\n","        if val_acc > best_val_acc:\n","            best_val_acc = val_acc\n","            best_config  = (lr, wd)\n","            best_model   = model  # Model wiht the best validation accuracy\n","\n","print(f\"\\nBest config: lr={best_config[0]}, weight_decay={best_config[1]}\")\n","print(f\"Best validation accuracy: {best_val_acc:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2S4OuVrSbV_5","outputId":"ba5f30e5-327f-427d-f1bc-9335a7a17fe5"},"id":"2S4OuVrSbV_5","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Training MobileNetV3 with lr=0.001, weight_decay=0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/applications/mobilenet_v3.py:517: UserWarning: `input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n","  return MobileNetV3(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 54ms/step - accuracy: 0.2355 - loss: 0.0130 - val_accuracy: 0.4080 - val_loss: 1.5604\n","Epoch 2/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.3926 - loss: 0.0091 - val_accuracy: 0.3557 - val_loss: 1.6333\n","Epoch 3/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.4090 - loss: 0.0084 - val_accuracy: 0.3588 - val_loss: 1.6661\n","Epoch 4/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.4528 - loss: 0.0077 - val_accuracy: 0.4165 - val_loss: 1.4676\n","Epoch 5/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.4732 - loss: 0.0075 - val_accuracy: 0.4095 - val_loss: 1.5350\n","Epoch 6/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.4820 - loss: 0.0071 - val_accuracy: 0.4267 - val_loss: 1.4634\n","Epoch 7/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.4982 - loss: 0.0069 - val_accuracy: 0.4493 - val_loss: 1.4748\n","Epoch 8/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.5037 - loss: 0.0067 - val_accuracy: 0.4041 - val_loss: 1.5224\n","Epoch 9/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.5198 - loss: 0.0065 - val_accuracy: 0.3417 - val_loss: 1.6816\n","Epoch 10/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.5228 - loss: 0.0063 - val_accuracy: 0.3814 - val_loss: 1.6330\n"," → Best val_accuracy: 0.4493\n","\n","Training MobileNetV3 with lr=0.001, weight_decay=0.0001\n","Epoch 1/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 54ms/step - accuracy: 0.2429 - loss: 0.0146 - val_accuracy: 0.4048 - val_loss: 1.4858\n","Epoch 2/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.3681 - loss: 0.0103 - val_accuracy: 0.3947 - val_loss: 1.5099\n","Epoch 3/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.3986 - loss: 0.0095 - val_accuracy: 0.4251 - val_loss: 1.5058\n","Epoch 4/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.4250 - loss: 0.0092 - val_accuracy: 0.4462 - val_loss: 1.5359\n","Epoch 5/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.4173 - loss: 0.0090 - val_accuracy: 0.4181 - val_loss: 1.4742\n","Epoch 6/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.4362 - loss: 0.0088 - val_accuracy: 0.4368 - val_loss: 1.4826\n","Epoch 7/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.4426 - loss: 0.0088 - val_accuracy: 0.4727 - val_loss: 1.4361\n","Epoch 8/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.4430 - loss: 0.0087 - val_accuracy: 0.4883 - val_loss: 1.3623\n","Epoch 9/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.4514 - loss: 0.0086 - val_accuracy: 0.3479 - val_loss: 1.6541\n","Epoch 10/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.4485 - loss: 0.0086 - val_accuracy: 0.3643 - val_loss: 1.5948\n"," → Best val_accuracy: 0.4883\n","\n","Training MobileNetV3 with lr=0.0005, weight_decay=0.0\n","Epoch 1/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 54ms/step - accuracy: 0.2335 - loss: 0.0131 - val_accuracy: 0.3955 - val_loss: 1.6409\n","Epoch 2/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.3422 - loss: 0.0096 - val_accuracy: 0.4423 - val_loss: 1.4831\n","Epoch 3/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.3882 - loss: 0.0088 - val_accuracy: 0.3978 - val_loss: 1.5477\n","Epoch 4/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.4126 - loss: 0.0083 - val_accuracy: 0.4423 - val_loss: 1.4900\n","Epoch 5/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.4403 - loss: 0.0080 - val_accuracy: 0.4368 - val_loss: 1.4738\n"," → Best val_accuracy: 0.4423\n","\n","Training MobileNetV3 with lr=0.0005, weight_decay=0.0001\n","Epoch 1/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 54ms/step - accuracy: 0.1785 - loss: 0.0156 - val_accuracy: 0.3877 - val_loss: 1.6228\n","Epoch 2/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.3307 - loss: 0.0109 - val_accuracy: 0.4345 - val_loss: 1.5038\n","Epoch 3/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.3744 - loss: 0.0101 - val_accuracy: 0.4672 - val_loss: 1.4600\n","Epoch 4/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.3991 - loss: 0.0096 - val_accuracy: 0.4805 - val_loss: 1.4596\n","Epoch 5/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.4148 - loss: 0.0093 - val_accuracy: 0.4563 - val_loss: 1.4652\n","Epoch 6/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.4319 - loss: 0.0091 - val_accuracy: 0.4524 - val_loss: 1.4794\n","Epoch 7/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.4339 - loss: 0.0090 - val_accuracy: 0.4719 - val_loss: 1.4257\n"," → Best val_accuracy: 0.4805\n","\n","Best config: lr=0.001, weight_decay=0.0001\n","Best validation accuracy: 0.4883\n"]}]},{"cell_type":"code","source":["# Evaluate the best model on the test set\n","y_true = []\n","y_pred = []\n","for images, labels in test_ds:\n","    preds = best_model.predict(images)\n","    y_true.extend(labels.numpy()) # True labels\n","    y_pred.extend(np.argmax(preds, axis=1).tolist()) # Predictions\n","y_true = np.array(y_true)\n","y_pred = np.array(y_pred)\n","\n","# Compute metrics\n","acc       = accuracy_score(y_true, y_pred)\n","prec_w    = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n","rec_w     = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n","f1_w      = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n","\n","# Print results\n","print(\"\\nMobileNetV3 Test Results:\")\n","print(f\"Overall Test Accuracy : {acc:.4f}\")\n","print(f\"Weighted Precision   : {prec_w:.4f}\")\n","print(f\"Weighted Recall      : {rec_w:.4f}\")\n","print(f\"Weighted F1 Score    : {f1_w:.4f}\\n\")\n","print(classification_report(y_true, y_pred, target_names=class_names, zero_division=0))\n","\n","model_save_path = \"/content/best_mobilenetv3_model.keras\"\n","best_model.save(model_save_path) # Save best model\n","print(f\"Best MobileNetV3 model saved to: {model_save_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4437kw7tdjEc","outputId":"8b6c00a3-0068-4518-9a74-01206dcfb2f3"},"id":"4437kw7tdjEc","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n","\n","MobileNetV3 Test Results:\n","Overall Test Accuracy : 0.4976\n","Weighted Precision   : 0.5101\n","Weighted Recall      : 0.4976\n","Weighted F1 Score    : 0.4906\n","\n","              precision    recall  f1-score   support\n","\n","           A       0.33      0.38      0.35        29\n","           C       0.23      1.00      0.38        23\n","           D       0.52      0.49      0.51       162\n","           G       0.36      0.34      0.35        29\n","           H       0.00      0.00      0.00         9\n","           M       0.90      0.56      0.69        16\n","           N       0.63      0.60      0.61       291\n","           O       0.21      0.08      0.12        72\n","\n","    accuracy                           0.50       631\n","   macro avg       0.40      0.43      0.38       631\n","weighted avg       0.51      0.50      0.49       631\n","\n","Best MobileNetV3 model saved to: /content/best_mobilenetv3_model.keras\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}